import 'package:flutter/foundation.dart';
import 'package:record/record.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:io';
import '../models/audio_file.dart';
import '../services/api/audio_service.dart';
import 'recipe_provider.dart';

class AudioProvider extends ChangeNotifier {
  final AudioRecorder _audioRecord = AudioRecorder();
  final AudioService _audioService = AudioService();
  RecipeProvider? _recipeProvider;

  List<AudioFile> _audioFiles = [];
  bool _isLoading = false;
  bool _isRecording = false;
  bool _isUploading = false;
  String? _errorMessage;
  AudioFile? _currentProcessingAudio;
  String? _currentRecordingPath;
  bool _hasRecording = false;

  List<AudioFile> get audioFiles => _audioFiles;
  bool get isLoading => _isLoading;
  bool get isRecording => _isRecording;
  bool get isUploading => _isUploading;
  String? get errorMessage => _errorMessage;
  AudioFile? get currentProcessingAudio => _currentProcessingAudio;
  bool get hasRecording => _hasRecording;

  void setRecipeProvider(RecipeProvider recipeProvider) {
    _recipeProvider = recipeProvider;
  }

  Future<void> loadAudioFiles() async {
    _setLoading(true);
    _clearError();

    try {
      print('ğŸ” AudioProvider loadAudioFiles ì‹œì‘');
      final result = await _audioService.getAudioFiles();

      if (result.isSuccess && result.audioFiles != null) {
        _audioFiles = result.audioFiles!;
        print('âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ${_audioFiles.length}ê°œ ë¡œë“œ ì™„ë£Œ');
      } else {
        final errorMsg = result.message ?? 'ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.';
        print('âŒ ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: $errorMsg');
        _setError(errorMsg);
        _audioFiles = []; // Clear on error
      }
    } catch (e) {
      print('âŒ AudioProvider loadAudioFiles exception: $e');
      _setError('ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: $e');
      _audioFiles = [];
    } finally {
      _setLoading(false);
    }
  }

  Future<bool> startRecording() async {
    try {
      _clearError();

      // Check microphone permission
      if (!await _checkMicrophonePermission()) {
        _setError('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
        return false;
      }

      // Check if device has microphone
      if (!await _audioRecord.hasPermission()) {
        _setError('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
        return false;
      }

      // Create directory for recordings
      final directory = await getApplicationDocumentsDirectory();
      final recordingsDir = Directory('${directory.path}/recordings');
      if (!await recordingsDir.exists()) {
        await recordingsDir.create(recursive: true);
      }

      // Generate unique filename
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      _currentRecordingPath = '${recordingsDir.path}/recording_$timestamp.m4a';

      // Start recording
      await _audioRecord.start(
        const RecordConfig(
          encoder: AudioEncoder.aacLc,
          bitRate: 128000,
          sampleRate: 44100,
        ),
        path: _currentRecordingPath!,
      );

      _isRecording = true;
      _hasRecording = false;
      notifyListeners();

      debugPrint('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘: $_currentRecordingPath');
      return true;
    } catch (e) {
      _setError('ë…¹ìŒì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $e');
      debugPrint('âŒ ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜: $e');
      return false;
    }
  }

  Future<String?> stopRecording() async {
    try {
      _clearError();

      if (!_isRecording) {
        _setError('í˜„ì¬ ë…¹ìŒ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.');
        return null;
      }

      // Stop recording
      final path = await _audioRecord.stop();

      _isRecording = false;

      if (path != null && await File(path).exists()) {
        _currentRecordingPath = path;
        _hasRecording = true;
        debugPrint('âœ… ë…¹ìŒ ì™„ë£Œ: $path');
      } else {
        _setError('ë…¹ìŒ íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        _hasRecording = false;
        debugPrint('âŒ ë…¹ìŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨');
      }

      notifyListeners();
      return path;
    } catch (e) {
      _setError('ë…¹ìŒì„ ì¤‘ì§€í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: $e');
      _isRecording = false;
      _hasRecording = false;
      notifyListeners();
      debugPrint('âŒ ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: $e');
      return null;
    }
  }

  Future<bool> uploadAudioFile(String filePath) async {
    _setUploading(true);
    _clearError();

    try {
      // TODO: Implement audio upload
      // final result = await _audioService.uploadAudio(filePath);
      // if (result.isSuccess) {
      //   final audioFile = result.audioFile;
      //   _audioFiles.insert(0, audioFile);
      //   notifyListeners();
      //   return true;
      // } else {
      //   _setError(result.message);
      //   return false;
      // }

      // Mock successful upload
      await Future.delayed(const Duration(seconds: 2));
      return true;
    } catch (e) {
      _setError('íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      return false;
    } finally {
      _setUploading(false);
    }
  }

  Future<bool> processAudio(String audioId) async {
    _clearError();

    try {
      // Find the audio file
      final audioIndex = _audioFiles.indexWhere((audio) => audio.id == audioId);
      if (audioIndex == -1) {
        _setError('ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        return false;
      }

      // Update status to processing
      _audioFiles[audioIndex] = _audioFiles[audioIndex].copyWith(
        processingStatus: 'processing',
      );
      _currentProcessingAudio = _audioFiles[audioIndex];
      notifyListeners();

      // TODO: Implement API call to process audio
      // final result = await _audioService.processAudio(audioId);
      // if (result.isSuccess) {
      //   _audioFiles[audioIndex] = _audioFiles[audioIndex].copyWith(
      //     processingStatus: 'completed',
      //     transcriptText: result.transcriptText,
      //   );
      // } else {
      //   _audioFiles[audioIndex] = _audioFiles[audioIndex].copyWith(
      //     processingStatus: 'failed',
      //   );
      //   _setError(result.message);
      //   return false;
      // }

      // Mock processing
      await Future.delayed(const Duration(seconds: 3));
      _audioFiles[audioIndex] = _audioFiles[audioIndex].copyWith(
        processingStatus: 'completed',
        transcriptText: 'ì—„ë§ˆê°€ ì•Œë ¤ì£¼ì‹  ê¹€ì¹˜ì°Œê°œ ë ˆì‹œí”¼ì…ë‹ˆë‹¤...',
      );

      _currentProcessingAudio = null;
      notifyListeners();
      return true;
    } catch (e) {
      _setError('ìŒì„± ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
      _currentProcessingAudio = null;
      notifyListeners();
      return false;
    }
  }

  void deleteAudioFile(String audioId) {
    _audioFiles.removeWhere((audio) => audio.id == audioId);
    notifyListeners();
  }

  AudioFile? getAudioById(String audioId) {
    try {
      return _audioFiles.firstWhere((audio) => audio.id == audioId);
    } catch (e) {
      return null;
    }
  }

  void _setLoading(bool loading) {
    _isLoading = loading;
    notifyListeners();
  }

  void _setUploading(bool uploading) {
    _isUploading = uploading;
    notifyListeners();
  }

  void _setError(String error) {
    _errorMessage = error;
    notifyListeners();
  }

  void _clearError() {
    _errorMessage = null;
    notifyListeners();
  }

  void clearError() {
    _clearError();
  }

  // Upload and process current recording
  Future<bool> uploadAndProcessRecording() async {
    if (!_hasRecording || _currentRecordingPath == null) {
      _setError('ì—…ë¡œë“œí•  ë…¹ìŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.');
      return false;
    }

    try {
      _setUploading(true);
      _clearError();

      // Upload audio file
      debugPrint('ğŸ“¤ ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: $_currentRecordingPath');
      final uploadResult =
          await _audioService.uploadAudio(_currentRecordingPath!);

      if (!uploadResult.isSuccess) {
        _setError(uploadResult.message ?? 'íŒŒì¼ ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        return false;
      }

      debugPrint('âœ… ì˜¤ë””ì˜¤ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ');

      // Process audio for recipe extraction
      debugPrint('ğŸ”„ ìŒì„± ì²˜ë¦¬ ë° ë ˆì‹œí”¼ ìƒì„± ì‹œì‘');
      final processResult =
          await _audioService.processAudio(uploadResult.audioId!);

      if (!processResult.isSuccess) {
        _setError(processResult.message ?? 'ìŒì„± ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
        return false;
      }

      debugPrint('ğŸ‰ ë ˆì‹œí”¼ ìƒì„± ì™„ë£Œ');

      // Create recipe from processed audio
      if (_recipeProvider != null && processResult.recipeId != null) {
        await _recipeProvider!.createRecipeFromAudio(uploadResult.audioId!);
      }

      // Clear current recording
      _hasRecording = false;
      _currentRecordingPath = null;

      // Reload audio files
      await loadAudioFiles();

      return true;
    } catch (e) {
      _setError('ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: $e');
      debugPrint('âŒ ì—…ë¡œë“œ/ì²˜ë¦¬ ì˜¤ë¥˜: $e');
      return false;
    } finally {
      _setUploading(false);
    }
  }

  // Check microphone permission
  Future<bool> _checkMicrophonePermission() async {
    try {
      PermissionStatus permission = await Permission.microphone.status;

      if (permission.isDenied) {
        permission = await Permission.microphone.request();
      }

      if (permission.isPermanentlyDenied) {
        await openAppSettings();
        return false;
      }

      return permission.isGranted;
    } catch (e) {
      debugPrint('ê¶Œí•œ í™•ì¸ ì˜¤ë¥˜: $e');
      return false;
    }
  }

  // Dispose resources
  @override
  void dispose() {
    _audioRecord.dispose();
    super.dispose();
  }
}
